version: '3.8'

services:
  # Angular Frontend
  angular-app:
    build:
      context: ./angular
      dockerfile: Dockerfile
    container_name: atexo_angular_app
    ports:
      - "4200:4200"
    environment:
      NODE_ENV: production
    networks:
      - atexo_chatbot
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4200"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Flask Backend
  flask-app:
    build:
      context: ./flask
      dockerfile: Dockerfile
    container_name: atexo_flask_app
    ports:
      - "5000:5000"
    environment:
      FLASK_ENV: development
      FLASK_DEBUG: true
      MISTRAL_PREPROMPT: ${MISTRAL_PREPROMPT}
      WRENAI_BASE_URL: http://atexo_wren_ui:3000/api/v1
      WRENAI_API_KEY: your-wrenai-api-key
      KEYCLOAK_REALM: ${KEYCLOAK_REALM}
      KEYCLOAK_CLIENT_ID: ${KEYCLOAK_CLIENT_ID}
      KEYCLOAK_CLIENT_SECRET: ${KEYCLOAK_CLIENT_SECRET}
      KEYCLOAK_SERVER_URL: ${KEYCLOAK_SERVER_URL}
      JWT_SECRET_KEY: jwt-secret-key
      JWT_ALGORITHM: HS256
      AUTH_ENABLED: true
      
    networks:
      - atexo_chatbot
    env_file:
      - .env
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/chatbot/test"]
      interval: 30s
      timeout: 10s
      retries: 3

  # HAProxy Reverse Proxy (from reverse-proxy/docker-compose.yml)
  haproxy:
    build:
      context: ./reverse-proxy
      dockerfile: Dockerfile
    container_name: atexo_haproxy
    ports:
      #- "3000:3000"  # WrenAI UI
      - "8000:8000"  # WrenAI AI Service
      - "8001:8001"  # WrenAI Engine
      - "8002:8002"  # WrenAI Ibis Server
      - "8404:8404"  # HAProxy stats page
    environment:
      KEYCLOAK_URL: ${KEYCLOAK_SERVER_URL}
      KEYCLOAK_REALM: ${KEYCLOAK_REALM}
      KEYCLOAK_CLIENT_ID: ${KEYCLOAK_CLIENT_ID}
      KEYCLOAK_CLIENT_SECRET: ${KEYCLOAK_CLIENT_SECRET}
      KEYCLOAK_SERVICE_HOST: keycloak
      KEYCLOAK_SERVICE_PORT: 7080
      WREN_AI_SERVICE_PORT: 5555
      WREN_ENGINE_PORT: 8081
      IBIS_SERVER_PORT: 8000
      PROXY_TRUSTED_ADDRESSES: 172.16.0.0/12,192.168.0.0/16,10.0.0.0/8
      PROXY_HEADERS_TYPE: xforwarded
      ALLOW_STATIC_RESOURCES: true
      ALLOW_AUTH_ENDPOINTS: true
      STATIC_RESOURCE_PATHS: /_next,/static
      AUTH_ENDPOINT_PATHS: /api/auth,/realms,/resources,/admin
      JWT_CACHE_DURATION: 300
      JWT_VALIDATION_ENABLED: true
      JWT_LOG_LEVEL: info
      HAPROXY_STATS_USER: admin
      HAPROXY_STATS_PASSWORD: admin123
      HAPROXY_MAX_CONNECTIONS: 4096
      HAPROXY_LOG_LEVEL: info
    env_file:
      - .env
    depends_on:
      - wren-ui
      - wren-ai-service
      - wren-engine
      - ibis-server
    networks:
      - atexo_chatbot
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "haproxy", "-c", "-f", "/usr/local/etc/haproxy/haproxy.cfg"]
      interval: 30s
      timeout: 10s
      retries: 3

  # WrenAI Services (from wrenai/docker-compose.yaml)
  wren-bootstrap:
    image: ghcr.io/canner/wren-bootstrap:0.1.5
    container_name: atexo_wren_bootstrap
    restart: on-failure
    platform: ${PLATFORM}
    environment:
      DATA_PATH: /app/data
    env_file:
      - .env
    volumes:
      - wrenai_data:/app/data
    command: /bin/sh /app/init.sh
    networks:
      - atexo_chatbot

  wren-engine:
    image: ghcr.io/canner/wren-engine:0.17.1
    container_name: atexo_wren_engine
    restart: on-failure
    platform: ${PLATFORM}
    expose:
      - 8080
      - 7432
    env_file:
      - .env
    volumes:
      - wrenai_data:/usr/src/app/etc
      - ./wrenai/data:/usr/src/app/data
    networks:
      - atexo_chatbot
    depends_on:
      - wren-bootstrap

  ibis-server:
    image: ghcr.io/canner/wren-engine-ibis:0.17.1
    container_name: atexo_ibis_server
    restart: on-failure
    platform: ${PLATFORM}
    expose:
      - 8000
    env_file:
      - .env
    environment:
      WREN_ENGINE_ENDPOINT: http://wren-engine:8080
    volumes:
      - ./wrenai:/usr/src/app/data
    networks:
      - atexo_chatbot

  wren-ai-service:
    image: ghcr.io/canner/wren-ai-service:0.24.3
    container_name: atexo_wren_ai_service
    restart: on-failure
    platform: ${PLATFORM}
    expose:
      - 5555
    env_file:
      - .env
    environment:
      PYTHONUNBUFFERED: 1
      QDRANT_HOST: qdrant
      CONFIG_PATH: /app/config.yaml
      WREN_AI_SERVICE_PORT: 5555
      WREN_UI_PORT: 3000
      SHOULD_FORCE_DEPLOY: 1
    volumes:
      - ./wrenai/config.yaml:/app/config.yaml:ro
      - ./wrenai/data:/app/data:ro
    networks:
      - atexo_chatbot
    depends_on:
      - qdrant

  qdrant:
      image: qdrant/qdrant:v1.11.0
      container_name: atexo_qdrant
      restart: on-failure
      expose:
        - 6333
        - 6334
      volumes:
        - wrenai_data:/qdrant/storage
      networks:
        - atexo_chatbot

  wren-ui:
    image: ghcr.io/canner/wren-ui:0.30.0
    container_name: atexo_wren_ui
    restart: on-failure
    platform: ${PLATFORM}
    ports:
      - 3000:3000
    environment:
      DB_TYPE: sqlite
      SQLITE_FILE: /app/data/db.sqlite3
      WREN_ENGINE_ENDPOINT: http://wren-engine:8080
      WREN_AI_ENDPOINT: http://wren-ai-service:5555
      IBIS_SERVER_ENDPOINT: http://ibis-server:8000
      GENERATION_MODEL: gpt-4
      WREN_ENGINE_PORT: 8080
      WREN_AI_SERVICE_VERSION: 0.24.3
      WREN_UI_VERSION: 0.30.0
      WREN_ENGINE_VERSION: 0.17.1
      USER_UUID: default
      POSTHOG_API_KEY: 
      POSTHOG_HOST: 
      TELEMETRY_ENABLED: false
      NEXT_PUBLIC_USER_UUID: default
      NEXT_PUBLIC_POSTHOG_API_KEY: 
      NEXT_PUBLIC_POSTHOG_HOST: 
      NEXT_PUBLIC_TELEMETRY_ENABLED: false
      EXPERIMENTAL_ENGINE_RUST_VERSION: false
      WREN_PRODUCT_VERSION: 0.25.0
    env_file:
      - .env
    volumes:
      - wrenai_data:/app/data
    networks:
      - atexo_chatbot
    depends_on:
      - wren-ai-service
      - wren-engine

volumes:
  wrenai_data:

networks:
  atexo_chatbot:
    driver: bridge 